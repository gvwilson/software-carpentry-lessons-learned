\documentclass[10pt,a4paper,twocolumn]{article}
\usepackage{f1000_styles}
\usepackage{hyperref}
\usepackage{enumitem}

\newcommand{\fixme}[1]{\bf{FIXME: {#1}}}

\begin{document}

\title{Software Carpentry: Lessons Learned}
\author[1]{Greg Wilson}
\affil[1]{Software Carpentry Foundation / gvwilson@software-carpentry.org}

\maketitle
\thispagestyle{fancy}

\begin{abstract}

Since its start in 1998, Software Carpentry has evolved from a
week-long training course at the US national laboratories into a
worldwide volunteer effort to improve researchers' computing
skills. This paper explains what we have learned along the way, the
challenges we now face, and our plans for the future.

\end{abstract}
\clearpage

\section*{Introduction}

In January 2012, John Cook posted this to his widely-read blog
\cite{cook2012}:

\begin{quote}
In a review of linear programming solvers from 1987 to 2002, Bob Bixby
says that solvers benefited as much from algorithm improvements as from
Moore's law: ``Three orders of magnitude in machine speed and three
orders of magnitude in algorithmic speed add up to six orders of
magnitude in solving power. A model that might have taken a year to
solve 10 years ago can now solve in less than 30 seconds.''
\end{quote}

A million-fold speed-up is impressive, but hardware and algorithms are
only two sides of the iron triangle of programming. The third is
programming itself, and while improvements to languages, tools, and
practices have undoubtedly made software developers more productive
since 1987, the speed-up is percentages rather than orders of
magnitude.  Setting aside the minority who do high-performance
computing (HPC), the time it takes the ``desktop majority'' of
scientists to produce a new result is frequently dominated by how long
it takes to write, test, debug, install, and maintain software.

The problem is that most scientists are never taught how to do
this. Their undergraduate programs may include a generic introduction
to programming or a statistics or numerical methods course (in which
they are often expected to pick up programming on their own), but they
are almost never told that version control exists, and rarely if ever
shown how to structure a maintainable program, or how to turn the last
twenty commands they typed into a re-usable script. As a result, they
routinely spend hours doing things that could be done in minutes, or
don't do things at all because they don't know where to start
\cite{hannay2009,prabhu2011}.

This is where Software Carpentry comes in. We ran over 400 workshops
for over 12,000 researchers between January 2013 and July 2015. In
them, over 400 volunteer instructors helped attendees learn about
program design, task automation, version control, testing, and other
unglamorous but time-tested skills \cite{wilson2013}. Two independent
assessments in 2012 \cite{aranda2012,libarkin2012} and two others more
recently \cite{schossau2014,simperler2015} have shown that this
training is helping:

\begin{quote}
The program increases participants' computational understanding, as
measured by more than a two-fold (130\%) improvement in test scores
after the workshop. The program also enhances their habits and routines,
and leads them to adopt tools and techniques that are considered
standard practice in the software industry. As a result, participants
express extremely high levels of satisfaction with their involvement in
Software Carpentry (85\% learned what they hoped to learn; 95\% would
recommend the workshop to others).
\end{quote}

\section*{From Red to Green}

Like many projects, it has taken us years to become an overnight
success, and we have made many mistakes along the way.  These are best
understood historically.

\subsection*{Version 1: Red light}

In 1995-96, the author organized a series of articles in \emph{IEEE
Computational Science \& Engineering} titled, ``What Should Computer
Scientists Teach to Physical Scientists and Engineers?'' \cite{wilson1996}.
These grew out of the frustration he had working with scientists
who wanted to run before they could walk, i.e., to parallelize complex
programs that were not broken down into self-contained functions, that
did not have any automated tests, and that were not under version control
\cite{wilson2006a}.

In response, John Reynders (then director of the Advanced Computing
Laboratory at Los Alamos National Laboratory) invited the author and
Brent Gorda (now at Intel) to teach a week-long course to LANL staff.
This course ran for the first time in July 1998, and was repeated nine
times over the next four years. It eventually wound down as Gorda and
the author moved on to other projects, but two valuable lessons were
learned:

\begin{enumerate}

\item
  Intensive week-long courses are easy to schedule (particularly if
  instructors have to travel) but by the last two days, attendees'
  brains are full and learning drops off significantly.

\item
  Textbook software engineering is not useful to most scientists. In
  particular, careful documentation of requirements and lots of
  up-front design are not appropriate for people who (almost by
  definition) do not know what the right answer is yet. Agile
  development methods (which rose to prominence during this period)
  are a less bad fit to researchers' needs, but even they are not well
  suited to the common ``solo grad student'' model of working.

\end{enumerate}

\subsection*{Versions 2 and 3: Another Red Light}

The Software Carpentry course materials were updated and released in
2004-05 under a Creative Commons license with support from the
Python Software Foundation \cite{wilson2006b}. They were used twice in
a conventional term-long graduate course at the University of Toronto
aimed at a mix of students from Computer Science and the physical and
life sciences.

The materials attracted 1000-2000 unique visitors a month.  But while
graduate students (and the occasional faculty member) found the course
at Toronto useful, it never found an institutional home.  Most
Computer Science faculty believe that this basic material is too easy
to deserve a graduate credit (even though a significant minority of
their students, particularly those coming from non-CS backgrounds,
have no better software development skills than the average
physicist). Meanwhile, other departments believe that courses like
this ought to be offered by Computer Science, in the same way that
Mathematics and Statistics departments routinely offer service
courses.  In the absence of an institutional mechanism to offer credit
courses at some inter-departmental level, this course, like many other
interdisciplinary initiatives, fell between two stools.

\begin{quote}
\textbf{It works too well to be worth teaching}

Most computer scientists want to do research to advance our
understanding of the science of computing; things like command-line
history, tab completion, and ``select * from table'' have been around
too long, and work too well, to be interesting. As long as
universities reward research first, and teaching last, it is simply
not in most computer scientists' interests to offer courses like this.
\end{quote}

Secondly, despite repeated invitations, other people did not
contribute new material beyond an occasional bug report (a point which
we will return to \fixme{later}).

The most important lesson, though, was that while many faculty in
science, engineering, and medicine agree that their students should
learn more about computing, they \emph{won't} agree on what to take
out of the current curriculum to make room for it. A typical
undergraduate science degree in the US or Canada comprises roughly
1800 hours of class and laboratory time. Anyone who wants to add more
programming, statistics, writing, or anything else must either
lengthen the program (which is financially and institutionally
infeasible) or take something out. However, everything in the program
is there because it has a passionate defender who thinks it's vitally
important, and who is likely senior to those faculty advocating the
change.

\begin{quote}
\textbf{It adds up}

Saying, ``We'll just add a little computing to every other course,'' is
a cheat: five minutes per hour equals four entire courses in a four-year
program, which is unlikely to ever be implemented. Pushing computing
down to the high school level is also a non-starter, since that
curriculum is also full.
\end{quote}

The sweet spot for this kind of training is therefore the first years
of graduate school. At that point, students have time to learn (at
least, more time than they'll have once they're faculty) and real
problems of their own that they want to solve.

\subsection*{Version 4: Orange Light}

The author rebooted Software Carpentry in May 2010 with support from
several partners (see Table~\ref{t:launch-partners}). More than 120
short video lessons were recorded during the subsequent 12 months, and
six week-long classes were run for the backers. We also offered an
online class three times (a MOOC \emph{avant la lettre}).

This was our most successful version to date, in part because the
scientific landscape itself had changed. Open access publishing, crowd
sourcing, the data deluge in the life sciences, and growing concern
about reproducible research had convinced a growing number of
scientists that knowing how to program was now as important as knowing
how to do statistics.  Even most of them, though, still (rightly)
regarded it as a tax they had to pay in order to get their science
done.

Despite this round's overall success, there were several
disappointments:

\begin{enumerate}

\item
  Once again, we discovered that five eight-hour days are more wearying
  than enlightening.

\item
  And once again, only a handful of other people contributed material
  (see \fixme{below}).

\item
  Most importantly, the MOOC format didn't work: only 5-10\% of those
  who started with us completed the course, and the majority were
  people who already knew most of the material. Both figures are in
  line with completion rates and learner demographics for other MOOCs
  \cite{jordan2013}, but that does not make them less disappointing.

\end{enumerate}

The biggest take-away from this round was the need come up with a
scalable, sustainable model for delivering training. One instructor
simply can't reach enough people, and cobbling together funding from
half a dozen different sources every twelve to eighteen months is
risky as well as wearying.

\subsection*{Version 5: Green Light}

Software Carpentry rebooted again in January 2012 with a grant from
the Sloan Foundation to the Mozilla Foundation.  This time, the model
was two-day intensive workshops like those pioneered by The Hacker
Within, a grassroots group of grad students helping grad students at
the University of Wisconsin - Madison.

Shortening the workshops made it possible for more people to attend,
and increased the proportion of the material they could absorb. It
also forced us to think much harder about what skills scientists
really needed. Out went object-oriented programming, XML, Make, and
other topics.  Instead, we focused on a small set of tools (discussed
below) that let us introduce higher-level concepts without learners
really noticing (also discussed below).

Reaching more people allowed us to recruit new instructors from
workshop participants, which in turn allowed us to scale. Switching to
a ``host site covers costs'' model was equally important: funding was
still needed for 1.5 core staff to lead the project and match
instructors to workshops, but everything else funded itself.

\begin{quote}
\textbf{Learning to teach}

One of our most important discoveries during this period was that many
people are as interested in learning about better teaching practices
as they are in learning about computing.  The instructor training
program that we started in August 2012 has attracted hundreds of
participants, and at the time of writing there are over 400 more on
the waiting list.  This introduction to modern research in education
and evidence-based teaching practices \cite{hlw2010} doesn't just
improve our teaching: it also helps give the instructors a sense of
community and purpose.

\end{quote}

\subsection*{Version 6: A True Community Project}

In July 2014, the author ended his relationship with Mozilla and set
up the Software Carpentry Foundation, an independent non-profit
foundation under the auspices of NumFOCUS.  The SCF held its first
elections in January 2015, in which instructors who had taught over
the past two years selected seven of their own number as a Steering
Committee to oversee the project's operations.  Since then, the SCF
has formed partnerships with a growing number of institutions (see
Table~\ref{t:current-partners}), run an ever-increasing number of
workshops, and much more.

While the SCF is only nine months old, we have already learned many
things.  The most important are:

\begin{enumerate}

\item
  The first few people to join a volunteer organization are usually
  keener than those who join later.  As numbers grow, therefore, the
  time contributed per person will decrease, and structures must be
  designed with this in mind.  In particular, by the time there 400
  people are on the books, most will be dipping in and out of
  conversations rather than taking part on a daily or weekly basis, so
  frameworks and procedures must become simple and stable.

\item
  Every partner organization has different needs and
  constraints\footnote{We have learned much more than we ever wanted
    to about accounting rules at various universities\ldots}.
  ``Standard'' partnership agreements is essential therefore have to
  be treated as starting points for negotiation, rather than as ``take
  it or leave it'' propositions.

\item
  ``Bikeshedding'' is the practice of arguing over minor, marginal
  issues while more serious ones are overlooked.  It is a constant
  danger in an organization whose more vocal members actually enjoy
  programming, and would rather spend a week arguing about how to
  convert Markdown to PDF than an hour discussing whether to introduce
  functions before lists or vice versa.  Squelching these technical
  discussions is harmful because it has a chilling effect on
  conversation overall (and because we actually \emph{do} need to
  convert Markdown to PDF sometimes).  Letting them go unchecked,
  though, alienates people who would rather talk about teaching, or
  simply don't have enough time to go down technical rabbit holes.

\end{enumerate}

\subsection*{Data Carpentry}

The biggest recent development, though, has been the foundation of a
sibling organization called Data Carpentry in April 2014.  Where
Software Carpentry's mission is to help scientists who are programming
badly to program better, Data Carpentry's focus is, as its name
implies, to help them manage and analyze their data.  Led by
Dr.\ Tracy Teal, Data Carpentry was recently awarded \$700,000 by the
Moore Foundation, and is expected to grow rapidly over the coming two
years.

\subsection*{Results}

As we discuss below, we do not know how to measure the impact of our
workshops.  However, both their number, and the number of people
attending, have grown steadily:

\begin{figure}
\centering
\includegraphics[width=0.4\textwidth]{workshops.pdf}
\caption{Cumulative Number of Workshops \fixme{update}}
\label{f:workshops}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.4\textwidth]{enrolment.pdf}
\caption{Cumulative Enrolment \fixme{update}}
\label{f:enrolment}
\end{figure}

\begin{figure}
\centering
% \includegraphics[width=0.4\textwidth]{enrolment.pdf}
\caption{Cumulative Number of Instructors \fixme{update}}
\label{f:instructors}
\end{figure}

We are now a truly global organization (Table~\ref{t:by-country}).
And most importantly, feedback from participants is strongly positive.
While there are always problems with software set-up and the speed of
instruction (discussed below), 80-90\% of attendees typically report
that they were glad they attended and would recommend the workshops to
colleagues.

\section*{What we do}

So what does a typical workshop look like?

\begin{itemize}
\item
  \emph{Day 1 a.m.}: The Unix shell. We only show participants a dozen
  basic commands; the real aim is to introduce them to the idea of
  combining single-purpose tools (via pipes and filters) to achieve
  desired effects, and to getting the computer to repeat things (via
  command completion, history, and loops) so that people don't have
  to.
\item
  \emph{Day 1 p.m.}: Programming in Python, R, or MATLAB. (Only one
  language is taught in any given workshop.) The real goal is to show
  them when, why, and how to grow programs step-by-step as a set of
  comprehensible, reusable, and testable functions.
\item
  \emph{Day 2 a.m.}: Version control. We begin by emphasizing how this
  is a better way to back up files than creating directories with names
  like ``final'', ``really\_final'', ``really\_final\_revised'', and
  so on, then show them that it's also a better way to collaborate
  than FTP or Dropbox.
\item
  \emph{Day 2 p.m.}: Either more about programming in the workshop's
  chosen language, or an introduction to databases and SQL.  If the
  latter is chosen, the real goal is to show them what structured data
  actually is (in particular, why atomic values and keys are
  important) so that they will understand why it's important to store
  information this way.
\end{itemize}

As the descriptions above suggest, our real aim isn't to teach any
specific tool: it's to teach \emph{computational competence}. We can't
do this in the abstract: people won't show up for a hand-waving talk
about general principles because they won't believe those principles
will help them meet next Thursday's deadline.  Even if they do, they
won't understand, because big ideas need to be grounded in specific
examples to be comprehensible. If we show them how to solve a specific
problem with a specific tool, we can then lead into a larger
discussion of how scientists ought to develop, use, and curate
software.

There are a lot of local variations around the template shown above.
For example, some instructors use the command-line Python interpreter,
while others prefer the \href{https://jupyter.org/}{Jupyter Notebook}.
Still others teach R or MATLAB instead, while a handful of workshops
also cover tools such as LaTeX, or domain-specific topics such as
audio file processing, depending on the needs of the audience and the
expertise of the instructor.

We aim for no more than 40 people per room at a workshop, so that
every learner can receive personal attention when needed.  Where
possible, we run two or more rooms side by side, and use a
pre-assessment questionnaire to stream learners by prior experience,
which simplifies teaching and improves their experience.  We do
\emph{not} shuffle people from one room to another between the first
and second day: with the best inter-instructor coordination in the
world, doing so would result in lost context.

Our workshops are sometimes free, but most now charge a small
registration fee (typically \$20-40), primarily because it reduces the
no-show rate from a third to roughly 5\%.  When this is done, we must
be careful not to trip over institutional rules about commercial use
of their space: some universities will charge hundreds or thousands of
dollars per day for use of their classrooms if any money changes
hands.  As this is usually several times more than a small
registration fee would bring in, we usually choose the higher no-show
rate as the lesser evil\footnote{We have also experimented with
  refundable deposits, but the administrative overheads were
  unsustainable.  It also does not help get around the rules mentioned
  in the previous paragraph, since money still appears to be changing
  hands in the university's eyes.}.

\begin{quote}
\textbf{Commercial offerings}

Our material \cite{swcsite,swcgithub} is all covered by the Creative
Commons Attribution license, so anyone who wants to use it for
commercial training can do so without explicit permission from us. We
encourage this: if graduate students can help pay their bills by
sharing what they know, in the way that many programmers earn their
living by working on open source software, our community will only be
stronger.

What \emph{does} require permission is use of our name and logo, both
of which are trademarked.  Such permission is granted automatically if
at least one instructor is certified, the workshop covers three core
topics (the shell, version control, and a programming langauge), and
the organizers send us summary information (the dates, the location,
and the number of attendees).  We put these rules in place because of
people calling something ``Software Carpentry'' when they had nothing
to do with what we usually teach. We have worked hard to create
material that actually helps scientists, and to build some name
recognition around it, and we would like to make sure our name
continues to mean something.
\end{quote}

\begin{quote}
\textbf{Administration fees}

If the Software Carpentry Foundation helps to organize a workshop
(e.g., finds instructors and handles registration) then we charge the
host site a \$2500 administration fee.  This fee, which currently
provides about a quarter of our revenue, is routinely waived for
workshops in under-served areas and developing countries.  If host
sites organize the workshop themselves, we will still set up
registration and send out pre- and post-workshop questionnaires.
There is no fee in this case, but we do ask for a donation (we suggest
\$500).

\end{quote}

As well as instructors, we rely on local helpers to wander the room
and answer questions during practical sessions. These helpers may be
alumni of previous workshops who are interested in becoming
instructors, grad students who have picked up some or all of this on
their own, or members of the local open source community; where
possible, we aim to have at least one helper for every eight learners.

We find workshops go a lot better if people come in groups (e.g., 4-5
people from one lab) or have other pre-existing ties (e.g., are
working in the same field). They are less inhibited about asking
questions, and can support each other (morally and technically) when
the time comes to put what they've learned into practice after the
workshop is over. Group sign-ups also yield much higher turnout from
groups that are otherwise often under-represented, such as women and
minority students, since they know in advance that they will be in a
supportive environment.

\section*{Small things add up}

As in chess, success in teaching often comes from the accumulation of
seemingly small advantages. Here are a few of the things we do that we
believe have contributed to our success.

\subsection*{Live coding}

We teach via live coding rather than using slides: it's more
convincing, it enables instructors to be more responsive to ``what
if?'' questions, and it facilitates lateral knowledge transfer (i.e.,
people learn more than we realized we were teaching by watching how
instructors do things).  It takes a bit of practice for instructors to
get used to thinking aloud while coding in front of an audience, but
most report that it is then no more difficult to do than talking off a
deck of slides.

\begin{quote}
\textbf{One device good, two devices better}

Many instructors now use two devices when teaching: a laptop plugged
into the projector for learners to see, and a tablet beside it on
which they can view their notes and the Etherpad session (discussed
below).  This seems to be more reliable than displaying one virtual
desktop while flipping back and forth to another.
\end{quote}

\subsection*{Open everything}

Our grant proposals, mailing lists, feedback from workshops, and
everything else that isn't personally sensitive are out in the open
(see \cite{swcsite} for links).  While we cannot prove it, we believe
that the fact that people can see us actively succeeding, failing, and
learning earns us some credibility and respect.

\subsection*{Open lessons}

This is an important special case of the previous point. Anyone who
wants to use our lessons can take what we have, make changes, and offer
those back by sending us a pull request on GitHub. As mentioned earlier,
this workflow is still foreign to most educators, but it is allowing us
to scale and adapt more quickly and more cheaply than the centralized
approaches being taken by many high-profile online education ventures.

For example, we recently ``published'' our core lessons through
\href{https://zenodo.org/}{Zenodo}.  The number of contributors per
lesson is shown in Table~\ref{t:authors-per-lesson}.  The distribution
of contributions has the usual long-tail distribution, and while these
figures include a bit of double counting (since contributions to
templates show up in all lessons that use those templates), but the
fact remains that all of our lesson materials have had more
contributors than most massive ``open'' online courses, and are
stronger for it.

\subsection*{Use what we teach}

We also make a point of eating our own cooking, e.g., we use GitHub
for our web site and to plan workshops. Again, this buys us
credibility, and gives instructors a chance to do some hands-on
practice with the things they're going to teach.  Up until a year ago,
the (considerable) downside to this was that it could be difficult for
newcomers to contribute material.  We have simplified our templates
and build procedures considerably to fix this (with results discussed
above), and will be making more changes early in 2016 to incorporate
further insights.

One problem still to be addressed is the bikeshedding discussed
earlier.  Many contributors would rather spend days tweaking the build
process for lessons rather than an hour coming up with some new
self-test exercises for those same lessons, both because they are on
more familiar ground when debating programming issues, and because the
feedback loop is much tighter.  One of our goals for the coming year
is to push the bulk of discussion toward teaching practices and lesson
content.

\subsection*{Meet the learners on their own ground}

Learners tell us that it is important to them to leave the workshop
with their own working environment set up. We therefore continue to
teach on all three major platforms (Linux, Mac OS X, and Windows),
even though it would be simpler to require learners to use just
one. We have experimented with virtual machines on learners' computers
to reduce installation problems, but those introduce problems of their
own: older or smaller machines simply aren't fast enough.  We have
also tried using virtual machines (VMs) in the cloud, but this makes
us dependent on university-quality WiFi.

\subsection*{Collaborative note-taking}

We often use \href{http://etherpad.org}{Etherpad} for collaborative
note-taking and to share snippets of code and small data files with
learners. (If nothing else, it saves us from having to ask students to
copy long URLs from the presenter's screen to their computers.) It is
almost always mentioned positively in post-workshop feedback, and
several workshop participants have started using it in their own
teaching.

We are still trying to come up with an equally good way to share
larger files dynamically as the lessons progress.  Version control
does \emph{not} work, both because our learners are new to it (and
therefore likely to make mistakes that affect classmates) and because
classroom WiFi frequently can't handle a flurry of multi-megabyte
downloads.

\subsection*{Sticky notes and minute cards}

Giving each learner two sticky notes of different colors allows
instructors to do quick true/false questions as they're teaching. It
also allows real-time feedback during hands-on work: learners can put
a green sticky note on their laptop when they have something
completed, or a red one when they need help. We also use them as
minute cards: before each break, learners take a minute to write one
thing they've learned on the green sticky note, and one thing they
found confusing (or too fast or too slow) on the red. It only takes a
couple of minutes to collate these, and allows the instructors to
adjust to learners' interests and speed.

\subsection*{Pair programming}

Pairing is a good practice in real life, and an even better way to
teach: partners can not only help each other out during the practical,
but can also clarify each other's misconceptions when the solution is
presented, and discuss common research interests during breaks. To
facilitate this, we strongly prefer flat (dinner-style) seating to
banked (theater-style) seating; this also makes it easier for helpers
to reach learners who need assistance.

\subsection*{Diversity}

On June 24-25, 2013, we ran our first workshop for women in science,
engineering, and medicine. This event attracted 120 learners, 9
instructors, a dozen helpers, and direct sponsorship from several
companies, universities, and non-profit organizations. Our second such
workshop ran in March 2014, and we have done half a dozen of varying
sizes since.  While we do occasionally get complaints (mostly from
outsiders) about such events being discriminatory, they are
overwhelmed by the uniformly positive response from participants, many
of whom say that they would probably not have attended a mixed-gender
event because of previous bad experiences with tech meetups.

\section*{Instructor training}

We run a training course for would-be instructors to teach them how to
teach, and as mentioned above, this has proven extremely popular.  In
its original form, it took 2-4 hours/week of participants' time for
12-14 weeks (depending on scheduling interruptions); more recently, we
have run it both as a live two-day event, and as a two-day online
event, in which participants are together in groups of half a dozen or
more at one, two, or three sites, while the instructor takes part over
the web.

This training course introduces participants to the basics of
educational psychology, instructional design, and how these things
apply to teaching programming. It is necessarily very shallow, but
most participants find the material interesting as well as useful.  As
noted earlier, introducing grad students and faculty to evidence-based
teaching practices may turn out to be Software Carpentry's greatest
contribution.

\subsection*{Why teach?}

But why do people volunteer as instructors?

\begin{description}

\item[\emph{To make the world a better place.}]  The two things we
  need to get through the next hundred years are more science and more
  courage; by helping scientists do more in less time, we are helping
  with the former.

\item[\emph{To make their own lives better.}]  Our instructors are
  often asked by their colleagues to help with computing problems.
  The more those colleagues know, the more interesting those requests
  are.

\item[\emph{To build a reputation.}]  Showing up to run a workshop is
  a great way for people to introduce themselves to colleagues, and to
  make contact with potential collaborators. This is probably the most
  important reason from Software Carpentry's point of view, since it's
  what makes our model sustainable.

\item[\emph{To practice teaching.}]
  This is also important to people contemplating academic careers.
 
\item[\emph{To help diversify the pipeline.}]  Computing is 12-15\%
  female, and that figure has been \emph{dropping} since its high
  point in the 1980s \cite{wic}. Some of our instructors are
  involved in part because they want to help break that cycle by
  participating in activities like our workshops for women in science
  and engineering.

\item[\emph{To learn new things, or learn old things in more detail.}]
  Working alongside an instructor with more experience is a great way
  to learn more about the tools, as well as about teaching.

\item[\emph{It's fun.}]  Our instructors get to work with smart people
  who actually want to be in the room, and don't have to mark anything
  afterwards. It's a refreshing change from teaching undergraduate
  calculus\ldots{}

\end{description}

\section*{TODO}

We've learned a lot, and we're doing a much better job of reaching and
teaching people than we did three years ago, but there are still many
things we need to improve.

\subsection*{Long-term assessment}

Our biggest challenge is figuring out whether we are actually helping
scientists get more science done.  We believe we are, and
\cite{aranda2012,libarkin2012,schossau2014,simperler2015} all seem to
confirm this, but we have not yet done the long-term follow-up needed
to prove this. This is partly because of a lack of resources, but it
is also a genuinely hard problem: no one knows how to measure the
productivity of programmers, or the productivity of scientists, and
putting the two together doesn't make the unknowns cancel out.

\begin{quote}
\textbf{Meeting our own standards}

One of the reasons we need to do long-term follow-up is to find out
for our own benefit whether we're teaching the right things the right
way.  As just one example, some of us believe that Subversion is
significantly easier for novices to understand than Git because there
are fewer places data can reside and fewer steps in its normal
workflow. Others believe just as strongly that there is no difference,
or that Git is actually easier to learn. While the large social
network centered around GitHub is a factor in our choice as well, we
would obviously be able to make better decisions if we had more
quantitative data to base them on.
\end{quote}

\subsection*{Too slow \emph{and} too fast}

Our second biggest challenge is the diversity of our learners'
backgrounds and skill levels. No matter what we teach, and how fast or
how slow we go, 20\% or more of the room will be lost, and there's a
good chance that a different 20\% will be bored.

The obvious solution is to split people by level, but if we ask them
how much they know about particular things, they regularly under- or
over-estimate their knowledge.  We have therefore developed a short
pre-assessment questionnaire (listed in the appendix) that asks them
whether they could accomplish specific tasks.  While far from perfect,
it seems to work well enough for our purposes.

\subsection*{``Is it supposed to hurt this much?''}

Third, getting software installed is often harder than using it. This
is a hard enough problem for experienced users, but almost by
definition our audience is \emph{inexperienced}, and our learners
don't (yet) know about system paths, environment variables, the
half-dozen places configuration files can lurk on a modern system, and
so on. Combine that with two versions of Mac OS X, three of Windows,
and two oddball Linux distributions, and it's almost inevitable that
every time we introduce a new tool, it won't work as expected (or at
all) for at least one person in the room. Detailed documentation has
not proven effective: some learners won't read it (despite repeated
prompting), and no matter how detailed it is, it will be
incomprehensible to some, and lacking for others.

\begin{quote}
\textbf{Edit this}

And while it may seem like a trivial thing, editing text is always
harder than we expect. We don't want to encourage people to use naive
editors like Notepad, and the two most popular legacy editors on Unix
(Vi and Emacs) are both usability nightmares. We now recommend a
handful of GUI editors, but it remains a stumbling block.
\end{quote}

\subsection*{What vs.~how}

Fourth on our list is the tension between teaching the ``what'' and the
``how'' of programming. When we teach a scripting language like Python,
we have to spend time up front on syntax, which leaves us only limited
time for the development practices that we really want to focus on, but
which are hard to grasp in the abstract. By comparison, version control
and databases are straightforward: what you see is what you do is what
you get.

\subsection*{Testing}

Speaking of development practices, we no longer include software
testing in our core curriculum, despite believing that it's extremely
important.  The reason is that while the mechanics of unit testing
with an xUnit-style framework are straightforward, and it's easy to
come up with representative test cases for things like reformatting
data files, we don't know what to teach scientists about testing their
particular applications.  Once we've covered floating-point roundoff
and the need to use ``almost equal'' instead of ``exactly equal'', our
learners quite reasonably ask, ``What should I use as a tolerance for
my computation?'' for which nobody has a good answer.  An attempt in
2014-15 to collect shareable examples was unfruitful, but we hope to
take another run at this in 2016.

\subsection*{Watching vs.~doing}

Finally, we try to make our teaching as interactive as possible, but
we still don't give learners hands-on exercises as frequently as we
should.  We also don't give them as diverse a range of exercises as we
should, and those that we do give are often at the wrong level. This
is partly due to a lack of time, but disorganization is also a factor.

There is also a constant tension between having students do realistic
exercises drawn from actual scientific workflows, and giving them tasks
that are small and decoupled, so that failures are less likely and don't
have knock-on effects when they occur. This is exacerbated by the
diversity of learners in the typical workshop, though we hope that will
diminish as we organize and recruit along disciplinary lines instead of
geographically.

Computing education researchers have learned a lot in the past two
decades about why people find it hard to learn how to program, and how
to teach them more effectively
\cite{guzdial2010,guzdial2013,hazzan2011,porter2013,sorva2012}.  We
do our best to cover these ideas in our instructor training program,
but are less good about actually applying them in our workshops.

\subsection*{Less of a Problem}

One issue which is less of a problem than it used to be is financial
sustainability. The ``host site covers costs'' model scales naturally
with the number of workshops, while a growing number of organizations
are keen to partner with us, primarily to build local capacity to run
more workshops when and as needed.  While we do not wish to tempt
fate, the Software Carpentry Foundation does seem to be headed toward
financial stability.

\section*{Conclusions}

To paraphrase William Gibson, the future is already here: it's just
that the skills needed to implement it aren't evenly distributed. A
small number of scientists can easily build an application that scours
the web for recently-published data, launch a cloud computing node to
compare it to home-grown data sets, and push the result to a GitHub
account; others are still struggling to free their data from Excel and
figure out which of the nine backup versions of their paper is the one
they sent for publication.

The fact is, it's hard for scientists to do the cool things their
colleagues are excited about without basic computing skills, and
impossible for them to know what other new things are possible. Our
ambition is to change that: not just to make scientists more productive
today, but to allow them to be part of the changes that are transforming
science in front of our eyes. If you would like to help, we'd like to
hear from you: please mail us at admin@software-carpentry.org.

\subsection*{Competing Interests}

The author is an employee of the Software Carpentry Foundation. Over
the years, Software Carpentry has received support from the
organizations listed in Tables~\ref{t:launch-partners}
and~\ref{t:current-partners}, and from The Mathworks, Enthought Inc.,
Continuum Analytics, the Sloan Foundation, and the Mozilla Foundation.

\subsection*{Grant Information}

Software Carpentry is not currently supported by grants.

\subsection*{Acknowledgements}

The author wishes to thank Brent Gorda, who helped create Software
Carpentry sixteen years ago; the hundreds of people who have helped
organize and teach workshops over the years; and the thousands of
people who have taken a few days to learn how to get more science
done in less time, with less pain.

\nocite{*}
{\small\bibliographystyle{unsrt}
\bibliography{software-carpentry-lessons-learned}}

\section*{Tables}

\begin{table*}
\centering
\begin{tabular}{lll}
Indiana University & Michigan State University & Microsoft \\
MITACS & Queen Mary University of London & Scimatic \\
SciNet & SHARCNet & UK Met Office
\end{tabular}
\caption{Launch Partners (2010)}
\label{t:launch-partners}
\end{table*}

\begin{table*}
\centering
\begin{tabular}{lll}
Berkeley Institute for Data Science & Compute Canada & ELIXIR~UK \\
GitHub & Insight Data Science & iPlant \\
Lawrence Berkeley National Laboratory & Michigan State University & Netherlands eScience Center \\
New Zealand eScience Infrastructure & RStudio & Software Sustainability Institute \\
University College London & UCAR & University of California Davis \\
University of Florida & University of Leeds & University of Melbourne \\
University of Michigan & University of Oklahoma & University of Washington
\end{tabular}
\caption{Current Partners}
\label{t:current-partners}
\end{table*}

\begin{table*}
\centering
\begin{tabular}{lrr}
Country & Workshops & Instructors \\
United States & 216 & 232 \\
Canada & 59 & 52 \\
United Kingdom & 43 & 50 \\
Australia & 33 & 41 \\
Brazil & 9 & 2 \\
South Africa & 6 & 1 \\
New Zealand & 5 & 8 \\
Norway & 5 & 3 \\
Germany & 5 & 9 \\
South Korea & 4 & 1 \\
France & 3 & 3 \\
Poland & 3 & 5 \\
Switzerland & 3 & 0 \\
Italy & 2 & 1 \\
Netherlands & 2 & 0 \\
Spain & 2 & 3 \\
China & 1 & 1 \\
Cyprus & 1 & 0 \\
Denmark & 1 & 2 \\
Finland & 1 & 0 \\
Ghana & 1 & 0 \\
Indonesia & 1 & 0 \\
Jordan & 1 & 0 \\
Lebanon & 1 & 0 \\
Saudi Arabia & 1 & 0 \\
Sweden & 1 & 2 \\
Thailand & 1 & 2 \\
India & 0 & 1 \\
\end{tabular}
\caption{Workshops and Instructors by Country}
\label{t:by-country}
\end{table*}

\begin{table*}
\centering
\begin{tabular}{ll}
Topic & Contributors \\
Git & 55 \\
Mercurial & 25 \\
MATLAB & 28 \\
Python & 52 \\
R & 49 \\
Unix Shell & 64 \\
SQL & 41
\end{tabular}
\caption{Contributors per Lesson, 2014-15}
\label{t:authors-per-lesson}
\end{table*}

\end{document}

%------------------------------------------------------------

Piecemeal improvement may be normal in open source development, but
Wikipedia aside, it is still rare in other fields. In particular,
people often use one another's slide decks as starting points for
their own courses, but rarely offer their changes back to the original
author in order to improve them. This is partly because educators'
preferred file formats (Word, PowerPoint, and PDF) can't be handled
gracefully by existing version control systems, but more importantly,
there simply isn't a ``culture of contribution'' in higher education.

%------------------------------------------------------------

not least because creating videos is significantly more challenging
than creating slides. Editing or modifying them is harder still: while
a typo in a slide can be fixed by opening PowerPoint, making the
change, saving, and re-exporting the PDF, inserting new slides into a
video and updating the soundtrack seems to take at least half an hour
regardless of how small the change is.
